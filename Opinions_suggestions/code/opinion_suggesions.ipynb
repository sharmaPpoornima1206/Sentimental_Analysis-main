{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHluvF_VBnAN",
        "outputId": "71087e26-7942-4f79-a726-c246c2ffc95e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_Samples =  1000\n",
            "y_Samples =  1000\n",
            "Labels ={'suggestion', 'opinion', 'other', 'both'}\n",
            "count_labels= 4\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import csv\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "set1 = set()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/DF_project/task2.2.csv\") as file:\n",
        "  reader = csv.reader(file, delimiter=',')\n",
        "  next(reader)\n",
        "  count = 0\n",
        "  set1 = set()\n",
        "  X_tmp =[]\n",
        "  y_tmp =[]\n",
        "  for line in reader:\n",
        "    #print(line)\n",
        "    y1 =[]\n",
        "    X_tmp.append(line[0].lower().strip())\n",
        "    count = count +1\n",
        "    y_tmp.append(line[1].lower().strip())\n",
        "    set1.add(line[1].lower().strip())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"X_Samples = \",len(X_tmp))\n",
        "print(\"y_Samples = \",len(y_tmp))\n",
        "\n",
        "\n",
        "print(f\"Labels ={set1}\")\n",
        "print(\"count_labels=\", len(set1))\n",
        "#print(X_tmp)\n",
        "#print(y_tmp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_txt_train, X_txt_test, y_train_text, y_test_text = train_test_split(X_tmp, y_tmp, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# converting into numpy arrays\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ihs8OCVNE9xG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary:\n",
        "# 1. Convert X_txt_train and X_txt_test to matricies of numbers (i.e., use CountVectorizer)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from warnings import simplefilter\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "#vec = CountVectorizer(ngram_range=(1,1))\n",
        "#vec = CountVectorizer(ngram_range=(1,2))\n",
        "\n",
        "vec =TfidfVectorizer(analyzer='word' , stop_words='english',)\n",
        "\n",
        "X_train = vec.fit_transform(X_txt_train) # This should be a matrix\n",
        "X_test = vec.transform(X_txt_test)   # This should be a matrix\n",
        "\n",
        "\n",
        "print(\"shapes\")\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "# Initialize the classifier LinearSVC \n",
        "\n",
        "model = LinearSVC()\n",
        "\n",
        "# Create the params with the C values\n",
        "\n",
        "params = {\"C\": [0.0001, 0.001, 0.001, 0.01, 0.1, 1, 10,100]}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "\n",
        "clf = GridSearchCV(model, param_grid=params, cv=5, scoring='f1_macro')\n",
        "\n",
        "# \"fit\" the model  on X_train\n",
        "\n",
        "clf.fit(X_train, y_train_text)\n",
        "\n",
        "validation_score = clf.best_score_  # Get the score from the GridSearchCV \"best score\"\n",
        "\n",
        "print(\"Validation F1: {:.4f}\".format(validation_score))\n",
        "\n",
        "svm_test_predictions =  clf.predict(X_test) # \"predict\" on X_test \n",
        "\n",
        "precision = precision_score(y_test_text, svm_test_predictions, average='macro')  # Get scores using svm_test_predictions and y_test with the precision_score method\n",
        "recall = recall_score(y_test_text, svm_test_predictions, average='macro')\n",
        "f1 = f1_score(y_test_text, svm_test_predictions, average='macro')\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1: {:.4f}\".format(f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UWWAZ7XFTaG",
        "outputId": "ea4ec2e8-37f0-440c-909e-aecfe9b78021"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shapes\n",
            "(800, 2120)\n",
            "(200, 2120)\n",
            "Validation F1: 0.3087\n",
            "Precision: 0.3139\n",
            "Recall: 0.3163\n",
            "F1: 0.3113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression  scores for opinion & suggestion\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from warnings import simplefilter\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vec =TfidfVectorizer(analyzer='word' , stop_words='english',)\n",
        "\n",
        "X_train = vec.fit_transform(X_txt_train) # This should be a matrix\n",
        "X_test = vec.transform(X_txt_test)   # This should be a matrix\n",
        "\n",
        "\n",
        "print(\"shapes\")\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "# Initialize the classifier LinearSVC \n",
        "\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "\n",
        "clf =  LogisticRegression()\n",
        "\n",
        "# \"fit\" the model  on X_train\n",
        "\n",
        "clf.fit(X_train, y_train_text)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Validation F1: {:.4f}\".format(validation_score))\n",
        "\n",
        "svm_test_predictions =  clf.predict(X_test) # \"predict\" on X_test \n",
        "\n",
        "precision = precision_score(y_test_text, svm_test_predictions, average='macro')  # Get scores using svm_test_predictions and y_test with the precision_score method\n",
        "recall = recall_score(y_test_text, svm_test_predictions, average='macro')\n",
        "f1 = f1_score(y_test_text, svm_test_predictions, average='macro')\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1: {:.4f}\".format(f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTzG8JmxH-wf",
        "outputId": "e183454a-5660-4af6-baea-852df1b8d249"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shapes\n",
            "(800, 2120)\n",
            "(200, 2120)\n",
            "Validation F1: 0.3087\n",
            "Precision: 0.3111\n",
            "Recall: 0.3134\n",
            "F1: 0.3090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}