{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gdPaHmD6-0A"
      },
      "outputs": [],
      "source": [
        "# This tf-idf count vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO-XTzFg7omL",
        "outputId": "264cee3c-995e-48f8-80d5-fdfbe200392d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import csv\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/DF_project/Full_set.csv\") as file:\n",
        "  reader = csv.reader(file, delimiter=',')\n",
        "  next(reader)\n",
        "  count = 0\n",
        "  set1 = set()\n",
        "  X_tmp =[]\n",
        "  y_tmp =[]\n",
        "  for line in reader:\n",
        "    #print(line)\n",
        "    y1 =[]\n",
        "    X_tmp.append(line[0].lower().strip())\n",
        "    count = count +1\n",
        "    #new = line[1].split(\"|\")\n",
        "    #print(new)\n",
        "    y1.append(line[1].lower().strip())\n",
        "    set1.add(line[1].lower().strip())\n",
        "    if line[2] != '':\n",
        "      y1.append(line[2].lower().strip())\n",
        "    \n",
        "    y_tmp.append(y1)\n",
        "\n",
        "    #if count == 10:\n",
        "      #break\n",
        "\n",
        "print(\"X_Samples = \",len(X_tmp))\n",
        "print(\"y_Samples = \",len(y_tmp))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print(len(y_tmp))\n",
        "\n",
        "print(f\"Labels ={set1}\")\n",
        "print(\"count_labels=\", len(set1))\n",
        "\n",
        "#print(y_tmp)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7T9Q8O27E3J",
        "outputId": "c56d0262-91cd-476b-c828-35ed78b3a622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_Samples =  1000\n",
            "y_Samples =  1000\n",
            "Labels ={'enviro', 'mobility', 'cyber', 'ag', 'public', 'govt data', 'connect', 'dei', 'iot', 'other', 'util', 'edu'}\n",
            "count_labels= 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now splitting into train and test data\n",
        "\n",
        "X_txt_train, X_txt_test, y_train_text, y_test_text = train_test_split(X_tmp, y_tmp, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# converting into numpy arrays\n",
        "\n",
        "X_train = np.array(X_txt_train)\n",
        "X_test = np.array(X_txt_test)\n"
      ],
      "metadata": {
        "id": "SzRMSBWH7E-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wu7_JFdE7FFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "lb = preprocessing.MultiLabelBinarizer(classes=('other', 'iot', 'mobility', 'connect', 'edu', 'util', 'public', 'ag', 'cyber', 'govt data', 'enviro', 'dei'))\n",
        "y_train = lb.fit_transform(y_train_text)\n",
        "y_test = lb.transform(y_test_text)\n",
        "\n",
        "#print(y_test)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "classifier = Pipeline([\n",
        "('vec2', TfidfVectorizer(analyzer='word' , stop_words='english')),\n",
        "('tfidf', TfidfTransformer()),\n",
        "('clf', OneVsRestClassifier(LinearSVC()))])\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "predicted = classifier.predict(X_test)\n",
        "#print(predicted)\n",
        "print(\"Accuracy Score: \",accuracy_score(y_test, predicted))\n",
        "precision = precision_score(predicted,y_test,average=\"macro\") # Get scores using svm_test_predictions and y_test with the precision_score method\n",
        "recall = recall_score(predicted,y_test,average=\"macro\")\n",
        "f1 = f1_score(predicted,y_test,average=\"macro\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1: {:.4f}\".format(f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p07IEz5V7FI5",
        "outputId": "ef781e85-411c-4a65-8aab-60ba72022a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 12)\n",
            "(200, 12)\n",
            "Accuracy Score:  0.12\n",
            "Precision: 0.1352\n",
            "Recall: 0.3779\n",
            "F1: 0.1849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        }
      ]
    }
  ]
}